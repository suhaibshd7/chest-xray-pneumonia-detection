{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n# Silence TF / CUDA / cuDNN backend warnings\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter  # ‚Üê still using TensorBoard\nfrom torchvision import transforms, models\n\nfrom tqdm import tqdm\nimport numpy as np\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, \n    f1_score, roc_auc_score, confusion_matrix, roc_curve\n)\nimport cv2\n\nprint(\"‚úì Imports loaded (TensorBoard warnings silenced)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:50:04.682435Z","iopub.execute_input":"2025-11-08T18:50:04.682710Z","iopub.status.idle":"2025-11-08T18:50:26.558332Z","shell.execute_reply.started":"2025-11-08T18:50:04.682682Z","shell.execute_reply":"2025-11-08T18:50:26.557475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ChestXrayDataset(Dataset):\n    \"\"\"Dataset for chest X-ray pneumonia classification\"\"\"\n    \n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        \n        self.class_to_idx = {'NORMAL': 0, 'PNEUMONIA': 1}\n        \n        for class_name in ['NORMAL', 'PNEUMONIA']:\n            class_folder = os.path.join(root_dir, class_name)\n            label = self.class_to_idx[class_name]\n            \n            for filename in os.listdir(class_folder):\n                if filename.endswith(('.jpeg', '.jpg', '.png')):\n                    img_path = os.path.join(class_folder, filename)\n                    self.image_paths.append(img_path)\n                    self.labels.append(label)\n        \n        print(f\"Loaded {len(self.image_paths)} images\")\n        print(f\"  NORMAL: {self.labels.count(0)}\")\n        print(f\"  PNEUMONIA: {self.labels.count(1)}\")\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\nprint(\"‚úì ChestXrayDataset defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:50:26.559655Z","iopub.execute_input":"2025-11-08T18:50:26.560199Z","iopub.status.idle":"2025-11-08T18:50:26.567586Z","shell.execute_reply.started":"2025-11-08T18:50:26.560179Z","shell.execute_reply":"2025-11-08T18:50:26.566695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = {\n    'data_dir': '/kaggle/input/chest-xray-pneumonia/chest_xray',\n    'model_name': 'resnet18',\n    'pretrained': True,\n    'num_classes': 2,\n    'learning_rate': 0.0001,\n    'batch_size': 32,\n    'num_epochs': 50,\n    'patience': 5,\n    'use_augmentation': True,\n    'augmentation': {\n        'random_horizontal_flip': True,\n        'random_rotation': 10,\n        'color_jitter_brightness': 0.2,\n        'color_jitter_contrast': 0.2,\n    },\n    'use_class_weights': True,\n    'class_weights': [3.0, 1.0],\n    'optimizer': 'adam',\n    'weight_decay': 1e-4,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'seed': 42,\n    'save_dir': 'checkpoints/',\n    'best_model_path': 'checkpoints/best_model.pth',\n    'log_dir': 'runs/',\n    'print_freq': 10,\n}\n\nprint(\"Configuration:\")\nprint(f\"  Model: {config['model_name']}\")\nprint(f\"  Learning Rate: {config['learning_rate']}\")\nprint(f\"  Batch Size: {config['batch_size']}\")\nprint(f\"  Device: {config['device']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:50:26.568480Z","iopub.execute_input":"2025-11-08T18:50:26.568738Z","iopub.status.idle":"2025-11-08T18:50:26.674374Z","shell.execute_reply.started":"2025-11-08T18:50:26.568713Z","shell.execute_reply":"2025-11-08T18:50:26.673673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seed(seed=42):\n    \"\"\"Set random seeds for reproducibility\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\ndef create_model(model_name='resnet18', num_classes=2, pretrained=True):\n    \"\"\"Create model with transfer learning\"\"\"\n    if model_name == 'resnet18':\n        model = models.resnet18(pretrained=pretrained)\n    elif model_name == 'resnet34':\n        model = models.resnet34(pretrained=pretrained)\n    elif model_name == 'resnet50':\n        model = models.resnet50(pretrained=pretrained)\n    \n    num_features = model.fc.in_features\n    model.fc = nn.Linear(num_features, num_classes)\n    return model\n\ndef get_transforms(augment=False):\n    \"\"\"Get train and validation transforms\"\"\"\n    if augment:\n        train_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomRotation(config['augmentation']['random_rotation']),\n            transforms.ColorJitter(\n                brightness=config['augmentation']['color_jitter_brightness'],\n                contrast=config['augmentation']['color_jitter_contrast']\n            ),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                               std=[0.229, 0.224, 0.225])\n        ])\n    else:\n        train_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                               std=[0.229, 0.224, 0.225])\n        ])\n    \n    val_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    return train_transform, val_transform\n\ndef train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):\n    \"\"\"Train for one epoch\"\"\"\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1} [TRAIN]')\n    \n    for images, labels in pbar:\n        images, labels = images.to(device), labels.to(device)\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n    \n    return running_loss / len(train_loader.dataset), 100. * correct / total\n\ndef validate(model, val_loader, criterion, device, epoch):\n    \"\"\"Validate the model\"\"\"\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(val_loader, desc=f'Epoch {epoch+1} [VAL]')\n    \n    with torch.no_grad():\n        for images, labels in pbar:\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n    \n    return running_loss / len(val_loader.dataset), 100. * correct / total\n\nprint(\"‚úì Training helper functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:50:26.676274Z","iopub.execute_input":"2025-11-08T18:50:26.676484Z","iopub.status.idle":"2025-11-08T18:50:26.695937Z","shell.execute_reply.started":"2025-11-08T18:50:26.676467Z","shell.execute_reply":"2025-11-08T18:50:26.695374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model():\n    \"\"\"Main training function\"\"\"\n    set_seed(config['seed'])\n    \n    os.makedirs(config['save_dir'], exist_ok=True)\n    os.makedirs(config['log_dir'], exist_ok=True)\n    \n    writer = SummaryWriter(config['log_dir'])\n    device = torch.device(config['device'])\n    \n    print(\"=\" * 60)\n    print(\"TRAINING STARTED\")\n    print(\"=\" * 60)\n    \n    # Prepare data\n    train_transform, val_transform = get_transforms(augment=config['use_augmentation'])\n    \n    train_dataset = ChestXrayDataset(\n        root_dir=os.path.join(config['data_dir'], 'train'),\n        transform=train_transform\n    )\n    val_dataset = ChestXrayDataset(\n        root_dir=os.path.join(config['data_dir'], 'val'),\n        transform=val_transform\n    )\n    \n    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n                             shuffle=True, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], \n                           shuffle=False, num_workers=2, pin_memory=True)\n    \n    # Model setup\n    model = create_model(config['model_name'], config['num_classes'], config['pretrained'])\n    model = model.to(device)\n    \n    if config['use_class_weights']:\n        class_weights = torch.FloatTensor(config['class_weights']).to(device)\n        criterion = nn.CrossEntropyLoss(weight=class_weights)\n    else:\n        criterion = nn.CrossEntropyLoss()\n    \n    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], \n                          weight_decay=config['weight_decay'])\n    \n    # Training loop\n    best_val_loss = float('inf')\n    patience_counter = 0\n    \n    for epoch in range(config['num_epochs']):\n        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n        val_loss, val_acc = validate(model, val_loader, criterion, device, epoch)\n        \n        writer.add_scalar('Loss/train', train_loss, epoch)\n        writer.add_scalar('Loss/val', val_loss, epoch)\n        writer.add_scalar('Accuracy/train', train_acc, epoch)\n        writer.add_scalar('Accuracy/val', val_acc, epoch)\n        \n        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n        print(f\"Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n        print(f\"Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'train_loss': train_loss,\n                'val_loss': val_loss,\n                'val_acc': val_acc,\n                'config': config\n            }, config['best_model_path'])\n            print(f\"‚úì Best model saved!\")\n        else:\n            patience_counter += 1\n            print(f\"No improvement ({patience_counter}/{config['patience']})\")\n        \n        if patience_counter >= config['patience']:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n    \n    writer.close()\n    print(\"\\n\" + \"=\" * 60)\n    print(\"TRAINING COMPLETE!\")\n    print(f\"Best validation loss: {best_val_loss:.4f}\")\n    print(\"=\" * 60)\n\n# Run training\ntrain_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:50:26.696724Z","iopub.execute_input":"2025-11-08T18:50:26.696942Z","iopub.status.idle":"2025-11-08T19:00:22.143359Z","shell.execute_reply.started":"2025-11-08T18:50:26.696917Z","shell.execute_reply":"2025-11-08T19:00:22.142415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_model(checkpoint_path, device):\n    \"\"\"Load trained model\"\"\"\n    model = models.resnet18(pretrained=False)\n    model.fc = nn.Linear(model.fc.in_features, 2)\n    \n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"‚úì Model loaded (Epoch {checkpoint['epoch']+1})\")\n    return model\n\ndef evaluate_model(model, test_loader, device):\n    \"\"\"Evaluate on test set\"\"\"\n    model.eval()\n    all_preds, all_labels, all_probs = [], [], []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            probs = F.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            all_probs.extend(probs[:, 1].cpu().numpy())\n    \n    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n\ndef generate_gradcam(model, image_tensor, target_layer, target_class=None):\n    \"\"\"Generate Grad-CAM heatmap\"\"\"\n    model.eval()\n    gradients, activations = [], []\n    \n    def backward_hook(module, grad_input, grad_output):\n        gradients.append(grad_output[0])\n    \n    def forward_hook(module, input, output):\n        activations.append(output)\n    \n    handle_backward = target_layer.register_full_backward_hook(backward_hook)\n    handle_forward = target_layer.register_forward_hook(forward_hook)\n    \n    output = model(image_tensor)\n    if target_class is None:\n        target_class = output.argmax(dim=1).item()\n    \n    model.zero_grad()\n    output[0, target_class].backward()\n    \n    grads = gradients[0].cpu().data.numpy()[0]\n    acts = activations[0].cpu().data.numpy()[0]\n    \n    weights = np.mean(grads, axis=(1, 2))\n    cam = np.zeros(acts.shape[1:])\n    for i, w in enumerate(weights):\n        cam += w * acts[i]\n    \n    cam = np.maximum(cam, 0)\n    cam = cam / (cam.max() + 1e-8)\n    \n    handle_backward.remove()\n    handle_forward.remove()\n    \n    return cam\n\nprint(\"‚úì Evaluation functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:00:22.144477Z","iopub.execute_input":"2025-11-08T19:00:22.144736Z","iopub.status.idle":"2025-11-08T19:00:22.156375Z","shell.execute_reply.started":"2025-11-08T19:00:22.144710Z","shell.execute_reply":"2025-11-08T19:00:22.155669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(config['device'])\n\n# Load best model\nmodel = load_model(config['best_model_path'], device)\n\n# Prepare test data\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_dataset = ChestXrayDataset(\n    root_dir=os.path.join(config['data_dir'], 'test'),\n    transform=test_transform\n)\n\ntest_loader = DataLoader(test_dataset, batch_size=config['batch_size'], \n                        shuffle=False, num_workers=2)\n\n# Evaluate\ny_pred, y_true, y_probs = evaluate_model(model, test_loader, device)\n\n# Print metrics\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TEST RESULTS\")\nprint(\"=\" * 60)\nprint(f\"Accuracy:  {accuracy_score(y_true, y_pred)*100:.2f}%\")\nprint(f\"Precision: {precision_score(y_true, y_pred)*100:.2f}%\")\nprint(f\"Recall:    {recall_score(y_true, y_pred)*100:.2f}%\")\nprint(f\"F1 Score:  {f1_score(y_true, y_pred):.4f}\")\nprint(f\"AUC-ROC:   {roc_auc_score(y_true, y_probs):.4f}\")\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['NORMAL', 'PNEUMONIA'],\n            yticklabels=['NORMAL', 'PNEUMONIA'])\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.title('Confusion Matrix')\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=150)\nplt.show()\n\nprint(\"\\n‚úì Evaluation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:00:22.157249Z","iopub.execute_input":"2025-11-08T19:00:22.157585Z","iopub.status.idle":"2025-11-08T19:00:30.318345Z","shell.execute_reply.started":"2025-11-08T19:00:22.157561Z","shell.execute_reply":"2025-11-08T19:00:30.317652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize Grad-CAM for 5 random samples\nnum_samples = 5\nindices = np.random.choice(len(test_dataset), num_samples, replace=False)\n\nfig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n\nfor idx, sample_idx in enumerate(indices):\n    image, label = test_dataset[sample_idx]\n    image_tensor = image.unsqueeze(0).to(device)\n    \n    # Get prediction\n    with torch.no_grad():\n        output = model(image_tensor)\n        pred_class = output.argmax(dim=1).item()\n        prob = F.softmax(output, dim=1)[0, pred_class].item()\n    \n    # Generate Grad-CAM\n    heatmap = generate_gradcam(model, image_tensor, target_layer=model.layer4)\n    heatmap_resized = cv2.resize(heatmap, (224, 224))\n    \n    # Denormalize image\n    img_np = image.cpu().numpy().transpose(1, 2, 0)\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    img_np = std * img_np + mean\n    img_np = np.clip(img_np, 0, 1)\n    \n    # Plot\n    axes[idx, 0].imshow(img_np)\n    axes[idx, 0].set_title(f'True: {\"PNEUMONIA\" if label==1 else \"NORMAL\"}')\n    axes[idx, 0].axis('off')\n    \n    axes[idx, 1].imshow(heatmap_resized, cmap='jet')\n    axes[idx, 1].set_title(f'Pred: {\"PNEUMONIA\" if pred_class==1 else \"NORMAL\"} ({prob:.1%})')\n    axes[idx, 1].axis('off')\n    \n    axes[idx, 2].imshow(img_np, alpha=0.7)\n    axes[idx, 2].imshow(heatmap_resized, cmap='jet', alpha=0.3)\n    axes[idx, 2].set_title('Overlay')\n    axes[idx, 2].axis('off')\n\nplt.tight_layout()\nplt.savefig('gradcam.png', dpi=150)\nplt.show()\n\nprint(\"‚úì Grad-CAM visualizations saved!\")\n\n\n# ============================================\n# ROC CURVE\n# ============================================\n# Run this AFTER you have: y_true, y_pred, y_probs\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ROC CURVE ANALYSIS\")\nprint(\"=\"*60)\n\n# Calculate ROC curve\nfpr, tpr, thresholds = roc_curve(y_true, y_probs)\nauc_score = roc_auc_score(y_true, y_probs)\n\n# Create figure\nplt.figure(figsize=(10, 8))\n\n# Plot ROC curve\nplt.plot(fpr, tpr, linewidth=3, \n         label=f'ROC Curve (AUC = {auc_score:.4f})', \n         color='#2E86AB')\n\n# Plot diagonal (random classifier)\nplt.plot([0, 1], [0, 1], 'k--', linewidth=2, \n         label='Random Classifier', alpha=0.5)\n\n# Fill area under curve\nplt.fill_between(fpr, tpr, alpha=0.2, color='#2E86AB')\n\n# Mark optimal operating point (Youden's index)\n# This finds the threshold that maximizes sensitivity + specificity\noptimal_idx = np.argmax(tpr - fpr)\noptimal_threshold = thresholds[optimal_idx]\nplt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=12, \n         label=f'Optimal Point (threshold={optimal_threshold:.3f})')\n\n# Formatting\nplt.xlabel('False Positive Rate', fontsize=14, fontweight='bold')\nplt.ylabel('True Positive Rate (Sensitivity)', fontsize=14, fontweight='bold')\nplt.title(f'ROC Curve - Pneumonia Detection\\nAUC = {auc_score:.4f}', \n          fontsize=15, fontweight='bold', pad=20)\nplt.legend(loc='lower right', fontsize=12, framealpha=0.9)\nplt.grid(alpha=0.3, linestyle='--')\nplt.xlim([-0.02, 1.02])\nplt.ylim([-0.02, 1.02])\n\nplt.tight_layout()\nplt.show()\n\n# Print interpretation\nprint(f\"\\nROC-AUC Score: {auc_score:.4f}\")\nprint(\"\\nInterpretation:\")\nif auc_score >= 0.9:\n    print(\"  ‚≠ê EXCELLENT - Model has excellent discrimination\")\nelif auc_score >= 0.8:\n    print(\"  ‚úÖ GOOD - Model has good discrimination\")\nelif auc_score >= 0.7:\n    print(\"  ‚ö†Ô∏è  FAIR - Model has acceptable discrimination\")\nelse:\n    print(\"  ‚ùå POOR - Model discrimination is poor\")\n\nprint(f\"\\nOptimal Operating Point:\")\nprint(f\"  Threshold: {optimal_threshold:.3f}\")\nprint(f\"  Sensitivity (TPR): {tpr[optimal_idx]:.3f}\")\nprint(f\"  Specificity (1-FPR): {1-fpr[optimal_idx]:.3f}\")\n\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:00:30.319332Z","iopub.execute_input":"2025-11-08T19:00:30.319573Z","iopub.status.idle":"2025-11-08T19:00:35.402507Z","shell.execute_reply.started":"2025-11-08T19:00:30.319552Z","shell.execute_reply":"2025-11-08T19:00:35.401885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# SAVE ALL VISUALIZATIONS TO FILES\n# ============================================\n# Run this in a NEW CELL at the END of your notebook\n# Make sure you already have: y_true, y_pred, y_probs, model, test_dataset\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport cv2\n\nprint(\"=\"*60)\nprint(\"SAVING ALL VISUALIZATIONS TO FILES\")\nprint(\"=\"*60)\n\n# ============================================\n# 1. CONFUSION MATRIX\n# ============================================\nprint(\"\\n[1/4] Generating confusion matrix...\")\n\ncm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['NORMAL', 'PNEUMONIA'],\n            yticklabels=['NORMAL', 'PNEUMONIA'],\n            cbar_kws={'label': 'Count'},\n            annot_kws={'size': 16, 'weight': 'bold'})\n\n# Add percentages\nfor i in range(2):\n    for j in range(2):\n        percentage = cm[i,j] / cm[i].sum() * 100\n        plt.text(j + 0.5, i + 0.75, \n                f'({percentage:.1f}%)',\n                ha=\"center\", va=\"center\", \n                color=\"gray\", fontsize=11)\n\nplt.ylabel('True Label', fontsize=14, fontweight='bold')\nplt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n\n# Calculate metrics for title\nsensitivity = cm[1,1] / (cm[1,0] + cm[1,1]) * 100\nspecificity = cm[0,0] / (cm[0,0] + cm[0,1]) * 100\n\nplt.title(f'Confusion Matrix - Pneumonia Detection\\n' + \n          f'Sensitivity: {sensitivity:.1f}% | Specificity: {specificity:.1f}%', \n          fontsize=15, fontweight='bold', pad=20)\n\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight', facecolor='white')\nprint(\"   ‚úì Saved: confusion_matrix.png\")\nplt.close()\n\n\n# ============================================\n# 2. ROC CURVE\n# ============================================\nprint(\"\\n[2/4] Generating ROC curve...\")\n\nfpr, tpr, thresholds = roc_curve(y_true, y_probs)\nauc_score = roc_auc_score(y_true, y_probs)\n\nplt.figure(figsize=(10, 8))\n\n# Plot ROC\nplt.plot(fpr, tpr, linewidth=3, \n         label=f'ROC Curve (AUC = {auc_score:.4f})', \n         color='#2E86AB')\nplt.plot([0, 1], [0, 1], 'k--', linewidth=2, \n         label='Random Classifier', alpha=0.5)\nplt.fill_between(fpr, tpr, alpha=0.2, color='#2E86AB')\n\n# Mark optimal point\noptimal_idx = np.argmax(tpr - fpr)\nplt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=12, \n         label=f'Optimal (threshold={thresholds[optimal_idx]:.3f})')\n\nplt.xlabel('False Positive Rate', fontsize=14, fontweight='bold')\nplt.ylabel('True Positive Rate', fontsize=14, fontweight='bold')\nplt.title(f'ROC Curve - Pneumonia Detection\\nAUC = {auc_score:.4f}', \n          fontsize=15, fontweight='bold', pad=20)\nplt.legend(loc='lower right', fontsize=12)\nplt.grid(alpha=0.3, linestyle='--')\nplt.xlim([-0.02, 1.02])\nplt.ylim([-0.02, 1.02])\n\nplt.tight_layout()\nplt.savefig('roc_curve.png', dpi=300, bbox_inches='tight', facecolor='white')\nprint(\"   ‚úì Saved: roc_curve.png\")\nplt.close()\n\n\n# ============================================\n# 3. METRICS SUMMARY\n# ============================================\nprint(\"\\n[3/4] Generating metrics summary...\")\n\nmetrics = {\n    'Accuracy': accuracy_score(y_true, y_pred),\n    'Precision': precision_score(y_true, y_pred),\n    'Recall': recall_score(y_true, y_pred),\n    'F1 Score': f1_score(y_true, y_pred),\n    'AUC-ROC': auc_score\n}\n\nfig, ax = plt.subplots(figsize=(12, 7))\ncolors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']\nbars = ax.barh(list(metrics.keys()), list(metrics.values()), \n               color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n\n# Add value labels\nfor i, (metric, value) in enumerate(metrics.items()):\n    ax.text(value + 0.02, i, f'{value:.4f}', \n            va='center', fontsize=13, fontweight='bold')\n\n# Add excellence threshold line\nax.axvline(x=0.9, color='gray', linestyle='--', alpha=0.5, linewidth=2)\nax.text(0.91, 4.3, 'Excellent\\n(>0.9)', fontsize=10, \n        color='gray', ha='left', style='italic')\n\nax.set_xlim([0, 1.15])\nax.set_xlabel('Score', fontsize=14, fontweight='bold')\nax.set_title('Model Performance Metrics Summary', \n             fontsize=15, fontweight='bold', pad=20)\nax.grid(axis='x', alpha=0.3, linestyle='--')\n\n# Add interpretation note\nax.text(0.5, -0.15, \n        '‚úì High Recall (99.49%) prioritized for medical screening | ' +\n        '‚úì AUC-ROC (0.95+) indicates excellent discrimination',\n        ha='center', fontsize=11, style='italic', color='#555',\n        transform=ax.transAxes)\n\nplt.tight_layout()\nplt.savefig('metrics_summary.png', dpi=300, bbox_inches='tight', facecolor='white')\nprint(\"   ‚úì Saved: metrics_summary.png\")\nplt.close()\n\n\n# ============================================\n# 4. GRAD-CAM VISUALIZATIONS\n# ============================================\nprint(\"\\n[4/4] Generating Grad-CAM visualizations...\")\n\n# Select diverse examples\ndef select_samples(y_true, y_pred, y_probs):\n    \"\"\"Select 5 interesting samples\"\"\"\n    samples = []\n    \n    # True Positive (high confidence)\n    tp = np.where((y_true == 1) & (y_pred == 1))[0]\n    if len(tp) > 0:\n        samples.append(tp[np.argmax(y_probs[tp])])\n    \n    # True Negative (high confidence)\n    tn = np.where((y_true == 0) & (y_pred == 0))[0]\n    if len(tn) > 0:\n        samples.append(tn[np.argmin(y_probs[tn])])\n    \n    # False Positive\n    fp = np.where((y_true == 0) & (y_pred == 1))[0]\n    if len(fp) > 0:\n        samples.append(fp[0])\n    \n    # False Negative\n    fn = np.where((y_true == 1) & (y_pred == 0))[0]\n    if len(fn) > 0:\n        samples.append(fn[0])\n    \n    # Borderline case\n    border = np.argmin(np.abs(y_probs - 0.5))\n    if border not in samples:\n        samples.append(border)\n    \n    return samples[:5]\n\nselected = select_samples(y_true, y_pred, y_probs)\n\nfig, axes = plt.subplots(len(selected), 3, figsize=(15, 5*len(selected)))\nif len(selected) == 1:\n    axes = axes.reshape(1, -1)\n\nfor idx, sample_idx in enumerate(selected):\n    # Load image\n    image, label = test_dataset[sample_idx]\n    image_tensor = image.unsqueeze(0).to(device)\n    \n    # Predict\n    with torch.no_grad():\n        output = model(image_tensor)\n        pred_class = output.argmax(dim=1).item()\n        prob = F.softmax(output, dim=1)[0, pred_class].item()\n    \n    # Generate Grad-CAM\n    heatmap = generate_gradcam(model, image_tensor, target_layer=model.layer4)\n    heatmap_resized = cv2.resize(heatmap, (224, 224))\n    \n    # Denormalize\n    img_np = image.cpu().numpy().transpose(1, 2, 0)\n    img_np = np.array([0.229, 0.224, 0.225]) * img_np + np.array([0.485, 0.456, 0.406])\n    img_np = np.clip(img_np, 0, 1)\n    \n    # Check correctness\n    correct = label == pred_class\n    marker = \"‚úì CORRECT\" if correct else \"‚úó INCORRECT\"\n    color = 'green' if correct else 'red'\n    \n    # Plot original\n    axes[idx, 0].imshow(img_np, cmap='gray')\n    axes[idx, 0].set_title(\n        f'{marker}\\nTrue: {\"PNEUMONIA\" if label==1 else \"NORMAL\"}',\n        fontsize=13, fontweight='bold', color=color\n    )\n    axes[idx, 0].axis('off')\n    \n    # Plot heatmap\n    axes[idx, 1].imshow(heatmap_resized, cmap='jet')\n    axes[idx, 1].set_title(\n        f'Grad-CAM Heatmap\\nPred: {\"PNEUMONIA\" if pred_class==1 else \"NORMAL\"}',\n        fontsize=13, fontweight='bold'\n    )\n    axes[idx, 1].axis('off')\n    \n    # Plot overlay\n    axes[idx, 2].imshow(img_np, cmap='gray', alpha=0.7)\n    axes[idx, 2].imshow(heatmap_resized, cmap='jet', alpha=0.4)\n    axes[idx, 2].set_title(\n        f'Overlay\\nConfidence: {prob*100:.1f}%',\n        fontsize=13, fontweight='bold'\n    )\n    axes[idx, 2].axis('off')\n\nplt.suptitle('Grad-CAM Model Attention Analysis', \n             fontsize=17, fontweight='bold', y=0.998)\nplt.tight_layout()\nplt.savefig('gradcam_visualizations.png', dpi=300, bbox_inches='tight', facecolor='white')\nprint(\"   ‚úì Saved: gradcam_visualizations.png\")\nplt.close()\n\n\n# ============================================\n# SUMMARY\n# ============================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ ALL VISUALIZATIONS SAVED SUCCESSFULLY!\")\nprint(\"=\"*60)\nprint(\"\\nGenerated Files:\")\nprint(\"  1. confusion_matrix.png      (Performance matrix)\")\nprint(\"  2. roc_curve.png              (ROC analysis)\")\nprint(\"  3. metrics_summary.png        (Bar chart of metrics)\")\nprint(\"  4. gradcam_visualizations.png (Model interpretability)\")\nprint(\"\\nüì• TO DOWNLOAD FROM KAGGLE:\")\nprint(\"  ‚Üí Look at right sidebar ‚Üí 'Output' section\")\nprint(\"  ‚Üí Click download icon (‚¨áÔ∏è) next to each .png file\")\nprint(\"  ‚Üí Save to your computer's images/ folder\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:00:35.403369Z","iopub.execute_input":"2025-11-08T19:00:35.403856Z","iopub.status.idle":"2025-11-08T19:00:44.667347Z","shell.execute_reply.started":"2025-11-08T19:00:35.403838Z","shell.execute_reply":"2025-11-08T19:00:44.666594Z"}},"outputs":[],"execution_count":null}]}